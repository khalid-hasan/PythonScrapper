from bs4 import BeautifulSoup
import requests
import math

url_list= []
activity_names= []
review_counts= []
activity_ids= []

url='https://www.klook.com/search?query=THAILAND&price_from=0&start=1&type=country'
headers = {'user-agent': 'my-app/0.0.1'}
source= requests.get(url, headers=headers).text

url_parse= BeautifulSoup(source, 'lxml')



# Scrap Activity Name
for content in url_parse.find_all('div', class_='m_justify_list'):
    try:
        url= content.a['href']

        f_url= url.split('/')[2]
        full_url=f'https://www.klook.com/activity/{f_url}'
        url_list.append(full_url)

        id_from_url= f_url.split("-")[0]
        activity_ids.append(id_from_url)
    except Exception as e:
        pass


for urls in url_list:
    url=urls
    headers = {'user-agent': 'my-app/0.0.1'}
    source= requests.get(url, headers=headers).text

    review_parse= BeautifulSoup(source, 'lxml')

    try:
        package_name = review_parse.find('h1', class_='t32').text
        activity_names.append(package_name)
        #print(package_name)

        no_of_reviews= review_parse.find('button', class_='j_goto_review more m_bg_white t14').text.split(" ")[2]
        review_counts.append(no_of_reviews)
        #print(no_of_reviews)
    except Exception as e:
        print("None")



# Scrap Reviews
for review_count in review_counts:
    total_page_count= math.ceil(review_count/10)
    page_no= 1

for activity_id in activity_ids:
    main_api=f'https://www.klook.com/xos_api/v1/usrcsrv/activities/{activity_id}/reviews?page={page_no}&limit=100'

    try:
        json_data = requests.get(main_api).json()

        for activity_name in activity_names:
            print("ACTIVITY_TITLE "+activity_name)
            for each in json_data['result']['item']:
                print(each['author'])
                print(each['content'])
                print()

            print()
    except Exception as e:
        pass
